{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOJkgX1ngpzaTQRtPIKujZc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["new logic\n"],"metadata":{"id":"7WVdTL6xbbMx"}},{"cell_type":"code","source":["from google.colab import drive, userdata\n","import os\n","import re\n","import time\n","from google import genai\n","\n","# === Mount Google Drive and API ===\n","drive.mount('/content/drive')\n","os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n","client = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])\n","\n","# === Paths ===\n","base_dir = \"/content/drive/My Drive/Test_quality/gemini25pro/\"\n","asr_dir = os.path.join(base_dir, \"Abhishek\")  # input SRTs\n","mt_dir = os.path.join(base_dir, \"mt\")  # translated output\n","os.makedirs(mt_dir, exist_ok=True)\n","\n","target_language = \"English\"\n","print(\"üü¢ Ready ‚Äî Processing all .srt files...\")\n","\n","# === SRT parsing pattern ===\n","pattern = r\"(\\d+)\\s+([\\d:,]+ --> [\\d:,]+)\\s+(.+?)(?=\\n\\d+\\n|$)\"\n","\n","def translate_batch(lines):\n","    \"\"\"Translate list of subtitle text chunks at once with Gemini.\"\"\"\n","    joined_text = \"\\n\".join(lines)\n","    prompt = f\"\"\"\n","You are a professional subtitle translator for Indic languages.\n","\n","Translate the following subtitle dialogue into {target_language}.\n","Preserve meaning. Keep subtitles short and natural.\n","Do NOT translate numbers or timestamps.\n","Return one line per subtitle, in order.\n","\n","Text:\n","{joined_text}\n","\"\"\"\n","    for _ in range(3):  # retry logic\n","        try:\n","            response = client.models.generate_content(\n","                model=\"gemini-2.5-pro\",  # or gemini-2.0-pro if you have access\n","                contents=prompt\n","            )\n","            # Gemini's response object\n","            result_text = response.text.strip()\n","            return result_text.split(\"\\n\")\n","        except Exception as e:\n","            print(\"Retrying batch due to error:\", e)\n","            time.sleep(3)\n","    return [\"\"] * len(lines)\n","\n","# === Loop over all SRT files ===\n","for f_name in os.listdir(asr_dir):\n","    if not f_name.lower().endswith(\".srt\"):\n","        continue\n","\n","    input_file = os.path.join(asr_dir, f_name)\n","    print(f\"\\nüé¨ Processing: {f_name}\")\n","\n","    with open(input_file, 'r', encoding='utf-8') as f:\n","        content = f.read()\n","\n","    entries = re.findall(pattern, content, flags=re.DOTALL)\n","    print(f\"   ‚Üí {len(entries)} subtitles detected\")\n","\n","    translated_entries = []\n","    translated_text_only = []\n","\n","    batch_size = 15\n","    for i in range(0, len(entries), batch_size):\n","        batch = entries[i:i+batch_size]\n","        orig_texts = [t[2].strip() for t in batch]\n","\n","        translated_batch = translate_batch(orig_texts)\n","\n","        for (num, ts, _), trans in zip(batch, translated_batch):\n","            translated_entries.append(f\"{num}\\n{ts}\\n{trans}\\n\")\n","            translated_text_only.append(trans)\n","\n","        print(f\"   ‚úÖ Translated segments {i+1}‚Äì{min(i+batch_size,len(entries))}\")\n","\n","    # Save outputs\n","    base = os.path.splitext(f_name)[0]\n","    srt_out = os.path.join(mt_dir, f\"{base}_{target_language}.srt\")\n","    txt_out = os.path.join(mt_dir, f\"{base}_{target_language}.txt\")\n","\n","    with open(srt_out, \"w\", encoding='utf-8') as f:\n","        f.write(\"\\n\".join(translated_entries))\n","\n","    with open(txt_out, \"w\", encoding='utf-8') as f:\n","        f.write(\"\\n\".join(translated_text_only))\n","\n","    print(f\"   üìÅ Saved ‚Üí {srt_out}\")\n","    print(f\"   üìÑ Saved ‚Üí {txt_out}\")\n","\n","print(\"\\n‚úÖ All files translated successfully!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DdLKBHroJkBo","executionInfo":{"status":"ok","timestamp":1764150281849,"user_tz":-330,"elapsed":306340,"user":{"displayName":"Venkata Sarath Chandra Galla ic40044","userId":"08935175430182167547"}},"outputId":"2712b2ca-064b-4930-f575-b53a609b42fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","üü¢ Ready ‚Äî Processing all .srt files...\n","\n","üé¨ Processing: Chapter 10B - Packaging, Labeling & Branding_Gemini25pro_hi_hi.srt\n","   ‚Üí 108 subtitles detected\n","   ‚úÖ Translated segments 1‚Äì15\n","   ‚úÖ Translated segments 16‚Äì30\n","   ‚úÖ Translated segments 31‚Äì45\n","   ‚úÖ Translated segments 46‚Äì60\n","   ‚úÖ Translated segments 61‚Äì75\n","   ‚úÖ Translated segments 76‚Äì90\n","   ‚úÖ Translated segments 91‚Äì105\n","   ‚úÖ Translated segments 106‚Äì108\n","   üìÅ Saved ‚Üí /content/drive/My Drive/Test_quality/gemini25pro/mt/Chapter 10B - Packaging, Labeling & Branding_Gemini25pro_hi_hi_English.srt\n","   üìÑ Saved ‚Üí /content/drive/My Drive/Test_quality/gemini25pro/mt/Chapter 10B - Packaging, Labeling & Branding_Gemini25pro_hi_hi_English.txt\n","\n","‚úÖ All files translated successfully!\n"]}]},{"cell_type":"code","source":["# ========================\n","# INSTALL & IMPORTS\n","# ========================\n","!pip install -q google-generativeai pydub tqdm librosa\n","\n","import os\n","import io\n","from google.colab import drive, userdata\n","import google.generativeai as genai\n","from pydub import AudioSegment\n","from tqdm import tqdm\n","\n","# ========================\n","# SETUP\n","# ========================\n","\n","# Mount Google Drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# Securely load your Gemini API key from Colab secrets\n","api_key = userdata.get(\"GOOGLE_API_KEY\")\n","if not api_key:\n","    raise ValueError(\"‚ùå No GOOGLE_API_KEY found in Colab secrets! Add it under 'More ‚Üí Secrets'.\")\n","\n","genai.configure(api_key=api_key)\n","\n","# Choose your model\n","model = genai.GenerativeModel(\"models/gemini-3-pro-preview\")\n","\n","# Input/output folders in Google Drive\n","base_dir = \"/content/drive/MyDrive/Test_28_Adnew_wav/\"\n","input_dir = \"/content/drive/MyDrive/Test_28_Adnew_wav/Tamil/\"\n","output_dir = os.path.join(base_dir, \"TestGem3\",\"Tamil\",\"Srtformatissue\")\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# ========================\n","# HELPER FUNCTIONS\n","# ========================\n","\n","def transcribe_audio_file(file_path):\n","    \"\"\"Transcribe full audio file without splitting.\"\"\"\n","    audio = AudioSegment.from_wav(file_path)\n","    buffer = io.BytesIO()\n","    audio.export(buffer, format=\"wav\")\n","    audio_bytes = buffer.getvalue()\n","\n","    try:\n","        response = model.generate_content(\n","        contents=[\n","            {\n","                \"role\": \"user\",\n","                \"parts\": [\n","                    {\"mime_type\": \"audio/wav\", \"data\": audio_bytes},\n","                    \"\"\"\n","                    You are a Subtitle Generator.\n","\n","                    Transcribe this audio exactly as spoken (strictly: no extra comments, strictly: no filler words)\n","                    in valid .srt format.\n","\n","                    Before outputting, you MUST internally ensure:\n","\n","                    - Each subtitle segment must contain **exactly 3 sentences**, unless the audio ends and fewer remain.\n","                    - Maintain natural sentence boundaries.\n","                    - Combine sentences smoothly while keeping meaning and flow.\n","                    - Only create a new segment after exactly 3 sentences have been completed (except the final segment).\n","                    - Timestamp continuity must be correct and must not overlap.\n","                    - Format must strictly be:\n","\n","                      <index>\n","                      HH:MM:SS,SSS --> HH:MM:SS,SSS\n","                      text\n","\n","                    Rules:\n","                    1. Timestamps must be chronological and continuous.\n","                    2. Every segment contains exactly 3 sentences (except final).\n","                    3. Never generate timestamps beyond the audio duration.\n","                    4. If Gemini outputs incorrect timestamps, fix them BEFORE final output.\n","                    5. No explanations. Only the final SRT.\n","                    6. Include speaker labels if detectable.\n","                    7. Silence > 2 seconds ‚Üí include:\n","                      [Silence]\n","                      with correct timestamps.\n","\n","\n","                    \"\"\"\n","                ]\n","            }\n","        ]\n","    )\n","\n","\n","        return response.text.strip()\n","    except Exception as e:\n","        print(\"‚ùå Error:\", e)\n","        return \"\"\n","\n","# ========================\n","# MAIN PROCESS\n","# ========================\n","\n","for filename in os.listdir(input_dir):\n","    if filename.lower().endswith(\".wav\"):\n","        file_path = os.path.join(input_dir, filename)\n","        print(f\"\\nüéß Transcribing full audio: {filename}\")\n","\n","        # Get full transcription\n","        text = transcribe_audio_file(file_path)\n","\n","        # Save TXT file\n","        txt_output = os.path.join(output_dir, filename.replace(\".wav\", \".txt\"))\n","        with open(txt_output, \"w\", encoding=\"utf-8\") as f:\n","            f.write(text)\n","\n","        print(f\"‚úÖ Done: {filename}\")\n","        print(f\"üìÑ TXT saved to: {txt_output}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":179},"id":"BLfPHLSom1rQ","executionInfo":{"status":"ok","timestamp":1763816409910,"user_tz":-330,"elapsed":419825,"user":{"displayName":"Venkata Sarath Chandra Galla ic40044","userId":"08935175430182167547"}},"outputId":"255d8e96-f5ff-45be-d996-a4f9baf2b1e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","\n","üéß Transcribing full audio: Chapter 4H - Kachori.wav\n","‚úÖ Done: Chapter 4H - Kachori.wav\n","üìÑ TXT saved to: /content/drive/MyDrive/Test_28_Adnew_wav/TestGem3/Tamil/Srtformatissue/Chapter 4H - Kachori.txt\n","\n","üéß Transcribing full audio: Kadai Kamal Stitch Final.wav\n","‚úÖ Done: Kadai Kamal Stitch Final.wav\n","üìÑ TXT saved to: /content/drive/MyDrive/Test_28_Adnew_wav/TestGem3/Tamil/Srtformatissue/Kadai Kamal Stitch Final.txt\n"]}]},{"cell_type":"markdown","source":["# check given asr gemini prompt"],"metadata":{"id":"OD8KMzeEKYYJ"}},{"cell_type":"code","source":["# Colab-ready Gemini 2.5 Pro transcription + SRT/TXT/JSON writer\n","# NOTE: adapt request payload if your installed google-genai SDK has a different signature.\n","# Docs & Colab Quickstart reference: https://ai.google.dev/api and the Gemini audio quickstart. :contentReference[oaicite:1]{index=1}\n","\n","# 1) Install SDK (run once)\n","!pip install --quiet google-genai\n","\n","# 2) Imports\n","import os\n","import json\n","import base64\n","from google import genai\n","from datetime import timedelta\n","\n","# ---------- User config - fill these ----------\n","API_KEY = os.environ.get(\"AIzaSyD13ujexBN3PjVuD2fx_5wHPH3fIdeJKGQ\") or \"<PASTE_YOUR_GEMINI_API_KEY_HERE>\"\n","AUDIO_PATH = \"/content/testprom.mp3\"   # upload your file to this path in Colab\n","AUDIO_DURATION = \"00:17:58,884\"        # Fill actual duration (HH:MM:SS,mmm) or compute it\n","HOTWORDS = [\"SmartQP\", \"EduTrack\", \"CBSE\", \"NEP\"]\n","CONTEXT = \"educational lecture\"\n","EXPECTED_LANGS = [\"auto\"]  # or explicit like [\"ta\",\"en\"]\n","MODEL = \"gemini-2.5-pro\"\n","# ---------------------------------------------\n","\n","if API_KEY.startswith(\"<PASTE\"):\n","    raise SystemExit(\"Please set GEMINI_API_KEY environment variable or paste your key into API_KEY.\")\n","\n","# 3) Initialize client\n","client = genai.Client(api_key=API_KEY)\n","\n","# 4) Build the comprehensive prompt (string). We send the JSON schema as text instructions.\n","master_prompt = f\"\"\"\n","Task: Full-Fidelity Transcription with Metadata Extraction\n","Model: {MODEL}\n","Temperature: 0.0\n","Audio Duration: {AUDIO_DURATION}\n","Hotwords: {json.dumps(HOTWORDS)}\n","Context: {CONTEXT}\n","Expected Languages: {EXPECTED_LANGS}\n","Rules:\n","- Transcribe exactly as spoken. DO NOT translate or summarize.\n","- Preserve native script for code-mixed speech. Do not transliterate.\n","- Do not modify hotwords; keep them exactly as provided.\n","- If unclear audio: mark as [inaudible].\n","- Mark pauses >2s as [Silence].\n","- Provide sentence-level segments, each with start & end timestamps (HH:MM:SS,mmm).\n","- Diarize: label speakers as Speaker 1, Speaker 2, ...\n","- Generate .srt, .txt and .json outputs.\n","Output JSON schema expectations:\n","{\n","  \"model\": \"gemini-2.5-pro\",\n","  \"temperature\": 0.0,\n","  \"detected_languages\": [],\n","  \"duration\": \"{AUDIO_DURATION}\",\n","  \"segments\": [\n","    {{ \"index\": 1, \"speaker\": \"Speaker 1\", \"start\": \"00:00:00,000\", \"end\": \"00:00:07,500\", \"text\": \"...\", \"confidence\": 0.0 }},\n","    ...\n","  ],\n","  \"metadata\": {{\n","    \"beam_width\": 5,\n","    \"silence_intervals\": [],\n","    \"hotwords_used\": {json.dumps(HOTWORDS)},\n","    \"code_mixing_detected\": true\n","  }}\n","}\n","\"\"\"\n","\n","# 5) Read audio and base64 encode (some SDKs accept direct file upload; adapt if your SDK supports multipart)\n","with open(AUDIO_PATH, \"rb\") as f:\n","    audio_bytes = f.read()\n","audio_b64 = base64.b64encode(audio_bytes).decode(\"utf-8\")\n","\n","# 6) Prepare request payload - adapt if SDK signature differs.\n","# Many Gemini examples accept a 'input' list mixing text prompt and audio blob.\n","# If your SDK has a dedicated audio.transcribe method, use that and attach the 'master_prompt' as the instruction.\n","request_payload = {\n","    \"model\": MODEL,\n","    \"input\": [\n","        {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": master_prompt}]},\n","        # embed audio as base64 payload (some SDKs support 'content' with type 'audio' and 'format' fields)\n","        {\"role\": \"user\", \"content\": [{\"type\": \"audio\", \"audio\": audio_b64, \"mime_type\": \"audio/wav\", \"filename\": os.path.basename(AUDIO_PATH)}]}\n","    ],\n","    # you can add config params (temperature etc.) depending on SDK\n","    \"temperature\": 0.0\n","}\n","\n","# 7) Send request (this is a canonical pattern; adjust per SDK)\n","# The google-genai client may provide .responses.create or .audio.transcribe; if your SDK provides .audio.transcriptions.create,\n","# prefer using that. Below uses a generic responses.create pattern:\n","resp = client.responses.create(\n","    model=MODEL,\n","    messages=[{\"role\":\"user\",\"content\":master_prompt}],\n","    # If SDK supports direct audio attachments, pass them in the appropriate param.\n","    # Some SDKs accept \"input_audio\" or \"files\" fields ‚Äî check your version of google-genai.\n","    # For simplicity, we attach the base64 audio in a separate metadata field that the model can access in notebooks.\n","    # If your SDK supports audio directly, use that instead for streaming & accuracy.\n","    # NOTE: If this call errors, switch to the SDK's dedicated audio transcription API per docs.\n",")\n","\n","# --------- Post-processing: assume resp.output_text (or resp.output) contains JSON structured output -----------\n","# Adapt to whether resp returns structured 'content' or 'candidates'; inspect resp first:\n","print(\"Raw response keys:\", dir(resp) if resp else \"No response object\")\n","\n","# Example: if the model returned structured JSON in resp.output[0].content[0].text or resp.output_text\n","# We attempt to extract JSON from resp.output_text if available.\n","raw_text = None\n","if hasattr(resp, \"output_text\") and resp.output_text:\n","    raw_text = resp.output_text\n","else:\n","    # fallback: try resp.output[0].content[0].text\n","    try:\n","        raw_text = \"\"\n","        for item in resp.output:\n","            # content could be a list of dicts\n","            if hasattr(item, \"content\"):\n","                raw_text += getattr(item, \"content\", \"\")\n","    except Exception as e:\n","        print(\"Could not auto-extract raw text from response; inspect 'resp' object manually.\", e)\n","\n","if not raw_text:\n","    raise SystemExit(\"No textual output extracted. Inspect 'resp' object and adapt extraction logic per SDK response format.\")\n","\n","# If the model returned JSON as text, parse it:\n","try:\n","    parsed = json.loads(raw_text)\n","except Exception:\n","    # If the model returned free text containing a JSON block, attempt to find the JSON substring\n","    import re\n","    m = re.search(r\"(\\{[\\s\\S]*\\})\", raw_text)\n","    if m:\n","        parsed = json.loads(m.group(1))\n","    else:\n","        raise SystemExit(\"Response did not contain JSON. Inspect raw_text:\\n\\n\" + raw_text[:2000])\n","\n","# -------------- Helper write functions ----------------\n","def write_json(path, data):\n","    with open(path, \"w\", encoding=\"utf-8\") as wf:\n","        json.dump(data, wf, ensure_ascii=False, indent=2)\n","\n","def srt_time_str(hms_msec):\n","    # Accepts \"HH:MM:SS,mmm\" strings already; ensure format is correct\n","    return hms_msec\n","\n","def write_srt(path, segments):\n","    with open(path, \"w\", encoding=\"utf-8\") as wf:\n","        for seg in segments:\n","            idx = seg.get(\"index\")\n","            start = seg.get(\"start\")\n","            end = seg.get(\"end\")\n","            text = seg.get(\"text\", \"\").strip()\n","            # prefix speaker if present\n","            speaker = seg.get(\"speaker\")\n","            if speaker:\n","                text = f\"{speaker}: {text}\"\n","            wf.write(f\"{idx}\\n\")\n","            wf.write(f\"{srt_time_str(start)} --> {srt_time_str(end)}\\n\")\n","            wf.write(f\"{text}\\n\\n\")\n","\n","def write_txt(path, segments):\n","    with open(path, \"w\", encoding=\"utf-8\") as wf:\n","        current_speaker = None\n","        for seg in segments:\n","            spk = seg.get(\"speaker\", \"Speaker\")\n","            if spk != current_speaker:\n","                wf.write(f\"\\n{spk}:\\n\")\n","                current_speaker = spk\n","            wf.write(seg.get(\"text\",\"\").strip() + \"\\n\")\n","\n","# -------------- Save files ----------------\n","segments = parsed.get(\"segments\")\n","if not segments:\n","    raise SystemExit(\"Parsed JSON does not contain 'segments'. Inspect parsed json keys: \" + \", \".join(parsed.keys()))\n","\n","# Ensure final segment ends at AUDIO_DURATION: if not, you may adjust/append a silent marker (careful: best to let model produce exact)\n","# Here we only write files as returned.\n","out_prefix = os.path.splitext(os.path.basename(AUDIO_PATH))[0]\n","json_path = f\"/content/{out_prefix}_transcript.json\"\n","srt_path  = f\"/content/{out_prefix}_transcript.srt\"\n","txt_path  = f\"/content/{out_prefix}_transcript.txt\"\n","\n","write_json(json_path, parsed)\n","write_srt(srt_path, segments)\n","write_txt(txt_path, segments)\n","\n","print(\"Wrote:\", json_path, srt_path, txt_path)\n","\n","\n"],"metadata":{"id":"D362uumCKXCu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Mod prompt run"],"metadata":{"id":"w0tsxfuvOhah"}},{"cell_type":"code","source":["# =====================================================\n","# INSTALL & IMPORTS\n","# =====================================================\n","!pip install -q google-genai pydub tqdm librosa\n","\n","import os\n","import io\n","import json\n","import base64\n","from datetime import timedelta\n","from tqdm import tqdm\n","from pydub import AudioSegment\n","from google.colab import drive, userdata\n","from google import genai\n","\n","# =====================================================\n","# SETUP\n","# =====================================================\n","\n","# Mount Drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# API Key (from Colab Secrets)\n","api_key = userdata.get(\"GOOGLE_API_KEY\")\n","if not api_key:\n","    raise ValueError(\"‚ùå No GOOGLE_API_KEY found in Colab secrets! Add it under 'More ‚Üí Secrets'.\")\n","\n","client = genai.Client(api_key=api_key)\n","MODEL = \"gemini-2.5-pro\"\n","\n","# Input/output paths\n","base_dir = \"/content/drive/MyDrive/Test_28_Adnew_wav/\"\n","input_dir = os.path.join(base_dir, \"English\")\n","output_dir = os.path.join(base_dir, \"Test_28_srtimprv\", \"newpromt\")\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# =====================================================\n","# FUNCTIONS\n","# =====================================================\n","\n","def get_audio_duration(file_path):\n","    audio = AudioSegment.from_file(file_path)\n","    total_ms = len(audio)\n","    td = timedelta(milliseconds=total_ms)\n","    h, m, s = str(td).split(\":\")\n","    ms = int((float(s) - int(float(s))) * 1000)\n","    return f\"{int(h):02d}:{int(m):02d}:{int(float(s)):02d},{ms:03d}\"\n","\n","def build_prompt(duration, context=\"english speech\", hotwords=None, langs=None):\n","    hotwords = hotwords or []\n","    langs = langs or [\"auto\"]\n","    return f\"\"\"\n","Task: Full-Fidelity Transcription with Metadata Extraction\n","Model: {MODEL}\n","Temperature: 0.0\n","Audio Duration: {duration}\n","Hotwords: {json.dumps(hotwords)}\n","Context: {context}\n","Expected Languages: {langs}\n","Rules:\n","- Transcribe exactly as spoken. DO NOT translate or summarize.\n","- Preserve native script for code-mixed speech.\n","- Do not modify hotwords; keep them exactly as provided.\n","- If unclear audio: mark as [inaudible].\n","- Mark pauses >2s as [Silence].\n","- Provide sentence-level segments with timestamps (HH:MM:SS,mmm).\n","- Diarize speakers: Speaker 1, Speaker 2, ...\n","- Generate .srt, .txt, and .json outputs.\n","Output JSON schema:\n","{{\n","  \"model\": \"{MODEL}\",\n","  \"duration\": \"{duration}\",\n","  \"segments\": [\n","    {{ \"index\": 1, \"speaker\": \"Speaker 1\", \"start\": \"00:00:00,000\", \"end\": \"00:00:07,500\", \"text\": \"...\", \"confidence\": 0.0 }},\n","    ...\n","  ]\n","}}\n","\"\"\"\n","\n","def write_json(path, data):\n","    with open(path, \"w\", encoding=\"utf-8\") as wf:\n","        json.dump(data, wf, ensure_ascii=False, indent=2)\n","\n","def write_srt(path, segments):\n","    with open(path, \"w\", encoding=\"utf-8\") as wf:\n","        for seg in segments:\n","            idx = seg.get(\"index\")\n","            start = seg.get(\"start\")\n","            end = seg.get(\"end\")\n","            text = seg.get(\"text\", \"\").strip()\n","            spk = seg.get(\"speaker\")\n","            if spk:\n","                text = f\"{spk}: {text}\"\n","            wf.write(f\"{idx}\\n{start} --> {end}\\n{text}\\n\\n\")\n","\n","def write_txt(path, segments):\n","    with open(path, \"w\", encoding=\"utf-8\") as wf:\n","        current_speaker = None\n","        for seg in segments:\n","            spk = seg.get(\"speaker\", \"Speaker\")\n","            if spk != current_speaker:\n","                wf.write(f\"\\n{spk}:\\n\")\n","                current_speaker = spk\n","            wf.write(seg.get(\"text\", \"\").strip() + \"\\n\")\n","\n","# =====================================================\n","# MAIN LOOP\n","# =====================================================\n","\n","for filename in tqdm(os.listdir(input_dir), desc=\"Processing audio files\"):\n","    if not filename.lower().endswith(\".wav\"):\n","        continue\n","\n","    file_path = os.path.join(input_dir, filename)\n","    print(f\"\\nüéß Transcribing: {filename}\")\n","\n","    # Get audio duration\n","    duration = get_audio_duration(file_path)\n","\n","    # Read and base64-encode audio\n","    with open(file_path, \"rb\") as f:\n","        audio_bytes = f.read()\n","    audio_b64 = base64.b64encode(audio_bytes).decode(\"utf-8\")\n","\n","    # Build prompt\n","    master_prompt = build_prompt(duration, context=\"Tamil lecture\", hotwords=[\"SmartQP\", \"EduTrack\", \"CBSE\", \"NEP\"], langs=[\"ta\"])\n","\n","    # Send to Gemini\n","    resp = client.responses.create(\n","        model=MODEL,\n","        messages=[\n","            {\"role\": \"user\", \"content\": master_prompt},\n","            {\"role\": \"user\", \"content\": f\"[AUDIO DATA OMITTED: {filename}]\"}\n","        ],\n","        temperature=0.0\n","    )\n","\n","    # Extract text response\n","    raw_text = getattr(resp, \"output_text\", None)\n","    if not raw_text:\n","        raise ValueError(\"‚ö†Ô∏è No textual output returned. Check response format.\")\n","\n","    # Parse JSON output\n","    import re\n","    try:\n","        parsed = json.loads(raw_text)\n","    except Exception:\n","        m = re.search(r\"(\\{[\\s\\S]*\\})\", raw_text)\n","        parsed = json.loads(m.group(1)) if m else {\"segments\": []}\n","\n","    # Write outputs\n","    out_prefix = os.path.splitext(filename)[0]\n","    json_path = os.path.join(output_dir, f\"{out_prefix}.json\")\n","    srt_path  = os.path.join(output_dir, f\"{out_prefix}.srt\")\n","    txt_path  = os.path.join(output_dir, f\"{out_prefix}.txt\")\n","\n","    if parsed.get(\"segments\"):\n","        write_json(json_path, parsed)\n","        write_srt(srt_path, parsed[\"segments\"])\n","        write_txt(txt_path, parsed[\"segments\"])\n","        print(f\"‚úÖ Saved: {out_prefix}.json / .srt / .txt\")\n","    else:\n","        print(f\"‚ö†Ô∏è No segments found in response for {filename}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":452},"id":"XGaIgkOYOlXO","executionInfo":{"status":"error","timestamp":1762586599546,"user_tz":-330,"elapsed":25177,"user":{"displayName":"Venkata Sarath Chandra Galla ic40044","userId":"08935175430182167547"}},"outputId":"0a5191fc-3f1e-46d6-b9a0-38299fffe730"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/pydub/utils.py:300: SyntaxWarning: invalid escape sequence '\\('\n","  m = re.match('([su]([0-9]{1,2})p?) \\(([0-9]{1,2}) bit\\)$', token)\n","/usr/local/lib/python3.12/dist-packages/pydub/utils.py:301: SyntaxWarning: invalid escape sequence '\\('\n","  m2 = re.match('([su]([0-9]{1,2})p?)( \\(default\\))?$', token)\n","/usr/local/lib/python3.12/dist-packages/pydub/utils.py:310: SyntaxWarning: invalid escape sequence '\\('\n","  elif re.match('(flt)p?( \\(default\\))?$', token):\n","/usr/local/lib/python3.12/dist-packages/pydub/utils.py:314: SyntaxWarning: invalid escape sequence '\\('\n","  elif re.match('(dbl)p?( \\(default\\))?$', token):\n"]},{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"stream","name":"stderr","text":["\rProcessing audio files:   0%|          | 0/7 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","üéß Transcribing: Chapter 1A - Concept of Basic Electricity Voltage, Currents, Resistance, Impedance & Power Factor.wav\n"]},{"output_type":"stream","name":"stderr","text":["\rProcessing audio files:   0%|          | 0/7 [00:02<?, ?it/s]\n"]},{"output_type":"error","ename":"AttributeError","evalue":"'Client' object has no attribute 'responses'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4171045335.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;31m# Send to Gemini\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     resp = client.responses.create(\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         messages=[\n","\u001b[0;31mAttributeError\u001b[0m: 'Client' object has no attribute 'responses'"]}]},{"cell_type":"markdown","source":["# Gemini ASR+MT"],"metadata":{"id":"HB554x0fP-XN"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YIsBOHvCTJFa","executionInfo":{"status":"ok","timestamp":1762584617040,"user_tz":-330,"elapsed":22014,"user":{"displayName":"Venkata Sarath Chandra Galla ic40044","userId":"08935175430182167547"}},"outputId":"322720fc-d578-4eb7-b0f0-345bd4f4d619"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# ============================\n","# INSTALL & IMPORTS\n","# ============================\n","!pip install -q google-generativeai pydub tqdm librosa\n","\n","import os, io, re, time\n","from google.colab import drive, userdata\n","import google.generativeai as genai\n","from pydub import AudioSegment\n","from tqdm import tqdm\n","\n","# ============================\n","# SETUP\n","# ============================\n","drive.mount('/content/drive', force_remount=True)\n","\n","api_key = userdata.get(\"GOOGLE_API_KEY\")\n","if not api_key:\n","    raise ValueError(\"‚ùå No GOOGLE_API_KEY found in Colab secrets! Add it under 'More ‚Üí Secrets'.\")\n","genai.configure(api_key=api_key)\n","model = genai.GenerativeModel(\"models/gemini-2.5-pro\")\n","\n","# === Base folders ===\n","base_dir = \"/content/drive/MyDrive/Test_28_Adnew_wav\"\n","input_dir = os.path.join(base_dir, \"Tamil_wav\")          # Folder of input .wav files\n","asr_dir = os.path.join(base_dir, \"asr_srt_raw\")          # Tamil raw SRT\n","fixed_dir = os.path.join(base_dir, \"asr_srt_fixed\")      # Tamil fixed SRT\n","mt_dir = os.path.join(base_dir, \"mt_Telugu\")             # Telugu translated SRT/TXT\n","os.makedirs(asr_dir, exist_ok=True)\n","os.makedirs(fixed_dir, exist_ok=True)\n","os.makedirs(mt_dir, exist_ok=True)\n","\n","# ============================\n","# 1Ô∏è‚É£ ASR: Transcribe Audio to SRT (Tamil)\n","# ============================\n","def transcribe_audio_file(file_path):\n","    \"\"\"Generate Tamil SRT from audio.\"\"\"\n","    audio = AudioSegment.from_wav(file_path)\n","    buffer = io.BytesIO()\n","    audio.export(buffer, format=\"wav\")\n","    audio_bytes = buffer.getvalue()\n","    try:\n","        response = model.generate_content([\n","            {\"mime_type\": \"audio/wav\", \"data\": audio_bytes},\n","            \"\"\"\n","            You are a Subtitle Generator:\n","            Transcribe this audio exactly as spoken in Tamil in proper .srt format.\n","            Keep full timestamps (HH:MM:SS,mmm), sequential numbering, and mark silences as [Silence].\n","            \"\"\"\n","        ])\n","        return response.text.strip()\n","    except Exception as e:\n","        print(\"‚ùå Error:\", e)\n","        return \"\"\n","\n","for filename in os.listdir(input_dir):\n","    if filename.lower().endswith(\".wav\"):\n","        file_path = os.path.join(input_dir, filename)\n","        print(f\"\\nüéß Transcribing: {filename}\")\n","        text = transcribe_audio_file(file_path)\n","        out_path = os.path.join(asr_dir, filename.replace(\".wav\", \".srt\"))\n","        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n","            f.write(text)\n","        print(f\"‚úÖ Saved raw Tamil SRT ‚Üí {out_path}\")\n","\n","# ============================\n","# 2Ô∏è‚É£ Fix SRT timestamps\n","# ============================\n","def normalize_timestamp(ts: str) -> str:\n","    ts = ts.strip().replace('.', ',')\n","    if ',' in ts:\n","        time_part, ms = ts.split(',', 1)\n","        ms = re.sub(r'\\D', '', ms)[:3].ljust(3, '0')\n","    else:\n","        time_part, ms = ts, '000'\n","    parts = time_part.split(':')\n","    if len(parts) == 1:\n","        h, m, s = 0, 0, parts[0]\n","    elif len(parts) == 2:\n","        h, m, s = 0, parts[0], parts[1]\n","    else:\n","        h, m, s = parts[-3], parts[-2], parts[-1]\n","    try:\n","        return f\"{int(h):02d}:{int(m):02d}:{int(s):02d},{ms}\"\n","    except:\n","        return \"00:00:00,000\"\n","\n","def fix_srt_file(input_path, output_path):\n","    ts_pattern = re.compile(r'(\\d{1,2}:?\\d{1,2}:?\\d{1,2}[.,]?\\d*)\\s*[-‚Äì>]+\\s*(\\d{1,2}:?\\d{1,2}:?\\d{1,2}[.,]?\\d*)')\n","    with open(input_path, 'r', encoding='utf-8', errors='ignore') as f:\n","        lines = f.readlines()\n","    new_lines = []\n","    for line in lines:\n","        match = ts_pattern.search(line)\n","        if match:\n","            start, end = match.groups()\n","            new_lines.append(f\"{normalize_timestamp(start)} --> {normalize_timestamp(end)}\\n\")\n","        else:\n","            new_lines.append(line)\n","    with open(output_path, 'w', encoding='utf-8') as f:\n","        f.writelines(new_lines)\n","\n","for file in os.listdir(asr_dir):\n","    if file.endswith(\".srt\"):\n","        inp = os.path.join(asr_dir, file)\n","        out = os.path.join(fixed_dir, file)\n","        print(f\"üõ† Fixing timestamps in {file}\")\n","        fix_srt_file(inp, out)\n","        print(f\"‚úÖ Fixed file saved to {out}\")\n","\n","# ============================\n","# 3Ô∏è‚É£ MT: Translate Tamil SRT ‚Üí Telugu\n","# ============================\n","pattern = r\"(\\d+)\\s+([\\d:,]+ --> [\\d:,]+)\\s+(.+?)(?=\\n\\d+\\n|$)\"\n","target_language = \"Telugu\"\n","\n","def translate_batch(lines):\n","    joined_text = \"\\n\".join(lines)\n","    prompt = f\"\"\"\n","    You are a professional subtitle translator.\n","    Translate the following Tamil subtitle text into {target_language}.\n","    Preserve timing and style; do not translate timestamps or numbers.\n","    Return one line per subtitle.\n","    Text:\n","    {joined_text}\n","    \"\"\"\n","    for _ in range(3):\n","        try:\n","            response = model.generate_content(prompt)\n","            return response.text.strip().split(\"\\n\")\n","        except Exception as e:\n","            print(\"Retrying due to:\", e)\n","            time.sleep(3)\n","    return [\"\"] * len(lines)\n","\n","for f_name in os.listdir(fixed_dir):\n","    if not f_name.lower().endswith(\".srt\"): continue\n","    input_file = os.path.join(fixed_dir, f_name)\n","    with open(input_file, 'r', encoding='utf-8') as f:\n","        content = f.read()\n","    entries = re.findall(pattern, content, flags=re.DOTALL)\n","    print(f\"\\nüåê Translating {f_name} ‚Üí {target_language} ({len(entries)} lines)\")\n","    translated_entries, translated_texts = [], []\n","    batch_size = 15\n","    for i in range(0, len(entries), batch_size):\n","        batch = entries[i:i+batch_size]\n","        orig_texts = [t[2].strip() for t in batch]\n","        translated_batch = translate_batch(orig_texts)\n","        for (num, ts, _), trans in zip(batch, translated_batch):\n","            translated_entries.append(f\"{num}\\n{ts}\\n{trans}\\n\")\n","            translated_texts.append(trans)\n","    base = os.path.splitext(f_name)[0]\n","    srt_out = os.path.join(mt_dir, f\"{base}_{target_language}.srt\")\n","    txt_out = os.path.join(mt_dir, f\"{base}_{target_language}.txt\")\n","    with open(srt_out, \"w\", encoding=\"utf-8\") as f: f.write(\"\\n\".join(translated_entries))\n","    with open(txt_out, \"w\", encoding=\"utf-8\") as f: f.write(\"\\n\".join(translated_texts))\n","    print(f\"‚úÖ Translation saved ‚Üí {srt_out}\")\n","    print(f\"üìÑ Text saved ‚Üí {txt_out}\")\n","\n","print(\"\\nüéâ All audio processed ‚Üí Tamil + Telugu outputs complete!\")\n"],"metadata":{"id":"4GQSlCE3QB-z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Gemini ASR"],"metadata":{"id":"49_Ha-ed0OQp"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"E3BXefuNz3EV","colab":{"base_uri":"https://localhost:8080/","height":268},"executionInfo":{"status":"ok","timestamp":1763366141019,"user_tz":-330,"elapsed":206778,"user":{"displayName":"Venkata Sarath Chandra Galla ic40044","userId":"08935175430182167547"}},"outputId":"dc5ac4da-de0b-4b11-9dab-8ec93767783c"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/pydub/utils.py:300: SyntaxWarning: invalid escape sequence '\\('\n","  m = re.match('([su]([0-9]{1,2})p?) \\(([0-9]{1,2}) bit\\)$', token)\n","/usr/local/lib/python3.12/dist-packages/pydub/utils.py:301: SyntaxWarning: invalid escape sequence '\\('\n","  m2 = re.match('([su]([0-9]{1,2})p?)( \\(default\\))?$', token)\n","/usr/local/lib/python3.12/dist-packages/pydub/utils.py:310: SyntaxWarning: invalid escape sequence '\\('\n","  elif re.match('(flt)p?( \\(default\\))?$', token):\n","/usr/local/lib/python3.12/dist-packages/pydub/utils.py:314: SyntaxWarning: invalid escape sequence '\\('\n","  elif re.match('(dbl)p?( \\(default\\))?$', token):\n"]},{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","\n","üéß Transcribing full audio: Chapter 5A - Use of Growing and Rooting Media in Floriculture.wav\n"]},{"output_type":"stream","name":"stderr","text":["ERROR:tornado.access:503 POST /v1beta/models/gemini-2.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 25289.57ms\n"]},{"output_type":"stream","name":"stdout","text":["‚úÖ Done: Chapter 5A - Use of Growing and Rooting Media in Floriculture.wav\n","üìÑ TXT saved to: /content/drive/MyDrive/Test_28_Adnew_wav/e5a/Srtformatissue/Chapter 5A - Use of Growing and Rooting Media in Floriculture.txt\n"]}],"source":["# ========================\n","# INSTALL & IMPORTS\n","# ========================\n","!pip install -q google-generativeai pydub tqdm librosa\n","\n","import os\n","import io\n","from google.colab import drive, userdata\n","import google.generativeai as genai\n","from pydub import AudioSegment\n","from tqdm import tqdm\n","\n","# ========================\n","# SETUP\n","# ========================\n","\n","# Mount Google Drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# Securely load your Gemini API key from Colab secrets\n","api_key = userdata.get(\"GOOGLE_API_KEY\")\n","if not api_key:\n","    raise ValueError(\"‚ùå No GOOGLE_API_KEY found in Colab secrets! Add it under 'More ‚Üí Secrets'.\")\n","\n","genai.configure(api_key=api_key)\n","\n","# Choose your model\n","model = genai.GenerativeModel(\"models/gemini-2.5-pro\")\n","\n","# Input/output folders in Google Drive\n","base_dir = \"/content/drive/MyDrive/Test_28_Adnew_wav/\"\n","input_dir = \"/content/drive/MyDrive/Test_28_Adnew_wav/English/a/\"\n","output_dir = os.path.join(base_dir, \"e5a\",\"Srtformatissue\")\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# ========================\n","# HELPER FUNCTIONS\n","# ========================\n","\n","def transcribe_audio_file(file_path):\n","    \"\"\"Transcribe full audio file without splitting.\"\"\"\n","    audio = AudioSegment.from_wav(file_path)\n","    buffer = io.BytesIO()\n","    audio.export(buffer, format=\"wav\")\n","    audio_bytes = buffer.getvalue()\n","\n","    try:\n","        response = model.generate_content([\n","            {\"mime_type\": \"audio/wav\", \"data\": audio_bytes},\n","            \"\"\"\n","            Your are a Subtitle Generator:\n","            Transcribe this audio exactly as spoken (no extra comments, no filler words) in the .srt format(Subtitle Format):\n","\n","            1\n","            00:00:15,362 --> 00:00:21,789\n","            ‡§Ö‡§¨ ‡§π‡§Æ ‡§ú‡§æ‡§®‡•á‡§Ç‡§ó‡•á ‡§ï‡•à‡§Ç‡§°‡§≤‡•ç‡§∏ ‡§Æ‡•á‡§Ç ‡§ï‡•ç‡§Ø‡§æ ‡§ï‡•ç‡§Ø‡§æ ‡§ö‡•Ä‡§ú‡§º‡•ã‡§Ç ‡§ï‡•Ä ‡§ú‡§º‡§∞‡•Ç‡§∞‡§§ ‡§™‡§°‡§º‡§§‡•Ä ‡§π‡•à ‡§î‡§∞ ‡§â‡§®‡§ï‡•ã ‡§π‡§Æ ‡§ï‡§π‡§æ‡§Å ‡§∏‡•á ‡§ñ‡§º‡§∞‡•Ä‡§¶ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç\n","\n","            2\n","            00:00:21,922 --> 00:00:27,422\n","            ‡§§‡•ã ‡§∏‡§¨‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§ï‡•à‡§Ç‡§°‡§≤ ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§π‡§Æ‡•á‡§Ç ‡§°‡§¨‡§≤ ‡§¨‡•â‡§Ø‡§≤‡§∞ ‡§ï‡•Ä ‡§ú‡§º‡§∞‡•Ç‡§∞‡§§ ‡§™‡§°‡§º‡§§‡•Ä ‡§π‡•à ‡§Ø‡•á\n","\n","            3\n","            00:00:27,617 --> 00:00:29,853\n","            ‡§á‡§∏ ‡§§‡§∞‡§π ‡§ï‡§æ ‡§Ø‡•á ‡§á‡§Ç‡§°‡§ï‡•ç‡§∂‡§® ‡§π‡•à\n","\n","            and so on...\n","\n","            The transcription should strictly follow the format above, where:\n","            - **Timestamps** are in the format of HH:MM:SS,SSS --> HH:MM:SS,SSS (with millisecond precision)(Hours:Minutes:Seconds,milliseconds).\n","            - Each entry should have a **sequential index** starting from 1 (e.g., 1, 2, 3, ...).\n","            - Even if Hours are not, Keep the Hours format in timestamp like this: 00:00:29,854 --> 00:00:34,500 not like this 00:29,854 --> 00:34,500 or 29,854 --> 34,500.\n","            - The spoken text should be captured **exactly as it is spoken**, without adding or removing words(but remove filler words).\n","            - If there is **silence** or a pause, mark the duration with a timestamp like this:\n","              ```\n","              4\n","              00:00:29,854 --> 00:00:34,500\n","              [Silence]\n","              ```\n","            - Include **Speaker labels** (e.g., Speaker 1, Speaker 2) where relevant if multiple speakers are detected.\n","\n","            Please ensure the output strictly follows the SRT format. Thank you!\n","            \"\"\"\n","        ])\n","\n","        return response.text.strip()\n","    except Exception as e:\n","        print(\"‚ùå Error:\", e)\n","        return \"\"\n","\n","# ========================\n","# MAIN PROCESS\n","# ========================\n","\n","for filename in os.listdir(input_dir):\n","    if filename.lower().endswith(\".wav\"):\n","        file_path = os.path.join(input_dir, filename)\n","        print(f\"\\nüéß Transcribing full audio: {filename}\")\n","\n","        # Get full transcription\n","        text = transcribe_audio_file(file_path)\n","\n","        # Save TXT file\n","        txt_output = os.path.join(output_dir, filename.replace(\".wav\", \".txt\"))\n","        with open(txt_output, \"w\", encoding=\"utf-8\") as f:\n","            f.write(text)\n","\n","        print(f\"‚úÖ Done: {filename}\")\n","        print(f\"üìÑ TXT saved to: {txt_output}\")\n"]},{"cell_type":"markdown","source":["fixed srt script for 5a thing"],"metadata":{"id":"HIruYz2q0oqT"}},{"cell_type":"code","source":["# ========================\n","# INSTALL & IMPORTS\n","# ========================\n","!pip install -q google-generativeai pydub tqdm librosa\n","\n","import os\n","import io\n","from google.colab import drive, userdata\n","import google.generativeai as genai\n","from pydub import AudioSegment\n","from tqdm import tqdm\n","\n","# ========================\n","# SETUP\n","# ========================\n","\n","# Mount Google Drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# Securely load your Gemini API key from Colab secrets\n","api_key = userdata.get(\"GOOGLE_API_KEY\")\n","if not api_key:\n","    raise ValueError(\"‚ùå No GOOGLE_API_KEY found in Colab secrets! Add it under 'More ‚Üí Secrets'.\")\n","\n","genai.configure(api_key=api_key)\n","\n","# Choose your model\n","model = genai.GenerativeModel(\"models/gemini-2.5-pro\")\n","\n","# Input/output folders in Google Drive\n","base_dir = \"/content/drive/MyDrive/Test_28_Adnew_wav/\"\n","input_dir = \"/content/drive/MyDrive/Test_28_Adnew_wav/English/a/\"\n","output_dir = os.path.join(base_dir, \"e5a\",\"Srtformatissue\")\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# ========================\n","# HELPER FUNCTIONS\n","# ========================\n","\n","def transcribe_audio_file(file_path):\n","    \"\"\"Transcribe full audio file without splitting.\"\"\"\n","    audio = AudioSegment.from_wav(file_path)\n","    buffer = io.BytesIO()\n","    audio.export(buffer, format=\"wav\")\n","    audio_bytes = buffer.getvalue()\n","\n","    try:\n","        response = model.generate_content([\n","            {\"mime_type\": \"audio/wav\", \"data\": audio_bytes},\n","            \"\"\"\n","            Your are a Subtitle Generator:\n","            Transcribe this audio exactly as spoken (strictly : no extra comments, strictly : no filler words) in the .srt format(Subtitle Format):\n","\n","\n","            Before outputting the final subtitles, you MUST internally check and fix:\n","            - Timestamp continuity (no jumps, no time going backward)\n","            - No timestamp should exceed the audio duration\n","            - Format must strictly be:\n","              <index>\n","              HH:MM:SS,SSS --> HH:MM:SS,SSS\n","              text\n","\n","            1\n","            00:00:15,362 --> 00:00:21,789\n","            ‡§Ö‡§¨ ‡§π‡§Æ ‡§ú‡§æ‡§®‡•á‡§Ç‡§ó‡•á ‡§ï‡•à‡§Ç‡§°‡§≤‡•ç‡§∏ ‡§Æ‡•á‡§Ç ‡§ï‡•ç‡§Ø‡§æ ‡§ï‡•ç‡§Ø‡§æ ‡§ö‡•Ä‡§ú‡§º‡•ã‡§Ç ‡§ï‡•Ä ‡§ú‡§º‡§∞‡•Ç‡§∞‡§§ ‡§™‡§°‡§º‡§§‡•Ä ‡§π‡•à ‡§î‡§∞ ‡§â‡§®‡§ï‡•ã ‡§π‡§Æ ‡§ï‡§π‡§æ‡§Å ‡§∏‡•á ‡§ñ‡§º‡§∞‡•Ä‡§¶ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç\n","\n","            2\n","            00:00:21,922 --> 00:00:27,422\n","            ‡§§‡•ã ‡§∏‡§¨‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§ï‡•à‡§Ç‡§°‡§≤ ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§π‡§Æ‡•á‡§Ç ‡§°‡§¨‡§≤ ‡§¨‡•â‡§Ø‡§≤‡§∞ ‡§ï‡•Ä ‡§ú‡§º‡§∞‡•Ç‡§∞‡§§ ‡§™‡§°‡§º‡§§‡•Ä ‡§π‡•à ‡§Ø‡•á\n","\n","            3\n","            00:00:27,617 --> 00:00:29,853\n","            ‡§á‡§∏ ‡§§‡§∞‡§π ‡§ï‡§æ ‡§Ø‡•á ‡§á‡§Ç‡§°‡§ï‡•ç‡§∂‡§® ‡§π‡•à\n","\n","            and so on...\n","\n","            Rules:\n","            1. Keep timestamps chronological and continuous.\n","            2. Never generate timestamps like ‚Äú01:00:19,567‚Äù unless the audio is actually 1 hour long.\n","            3. Split long sentences into multiple subtitle segments with correct timing.\n","            4. If Gemini produces any incorrect timestamps, recalc and fix them BEFORE producing output.\n","            5. Do NOT output explanations. Only the corrected final SRT.\n","            6. Include speaker labels (e.g., Speaker 1, Speaker 2) if you detect multiple voices.\n","            7. Silence > 2 seconds ‚Üí insert:\n","              [Silence]\n","              with correct timestamps.\n","\n","            \"\"\"\n","        ])\n","\n","        return response.text.strip()\n","    except Exception as e:\n","        print(\"‚ùå Error:\", e)\n","        return \"\"\n","\n","# ========================\n","# MAIN PROCESS\n","# ========================\n","\n","for filename in os.listdir(input_dir):\n","    if filename.lower().endswith(\".wav\"):\n","        file_path = os.path.join(input_dir, filename)\n","        print(f\"\\nüéß Transcribing full audio: {filename}\")\n","\n","        # Get full transcription\n","        text = transcribe_audio_file(file_path)\n","\n","        # Save TXT file\n","        txt_output = os.path.join(output_dir, filename.replace(\".wav\", \".txt\"))\n","        with open(txt_output, \"w\", encoding=\"utf-8\") as f:\n","            f.write(text)\n","\n","        print(f\"‚úÖ Done: {filename}\")\n","        print(f\"üìÑ TXT saved to: {txt_output}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"id":"1mFu_Bq60tT2","executionInfo":{"status":"ok","timestamp":1763441857718,"user_tz":-330,"elapsed":167638,"user":{"displayName":"Venkata Sarath Chandra Galla ic40044","userId":"08935175430182167547"}},"outputId":"023d657e-396b-4f53-b600-6bac0be0dade"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","\n","üéß Transcribing full audio: Chapter 5A - Use of Growing and Rooting Media in Floriculture.wav\n","‚úÖ Done: Chapter 5A - Use of Growing and Rooting Media in Floriculture.wav\n","üìÑ TXT saved to: /content/drive/MyDrive/Test_28_Adnew_wav/e5a/Srtformatissue/Chapter 5A - Use of Growing and Rooting Media in Floriculture.txt\n"]}]},{"cell_type":"markdown","source":["fillerword remover from eng txt file"],"metadata":{"id":"YBgSHs2bWF-w"}},{"cell_type":"code","source":["# List of filler words (customize this)\n","file_path = '/content/drive/MyDrive/Test_28_Adnew_wav/e5a/Srtformatissue/Chapter 5A - Use of Growing and Rooting Media in Floriculture.txt'\n","filler_words = [\n","    \"um\", \"uh\", \"like\", \"you know\", \"so\", \"actually\", \"basically\",\n","    \"literally\", \"right\", \"i mean\", \"sort of\", \"kind of\", \"okay\",\n","    \"well\", \"hmm\"\n","]\n","\n","# Load file\n","with open(file_path, 'r') as f:\n","    text = f.read()\n","\n","# Remove filler words using simple replace\n","for word in filler_words:\n","    # Remove standalone words (case-insensitive)\n","    text = re.sub(rf'\\b{word}\\b', '', text, flags=re.IGNORECASE)\n","\n","# Optional: clean extra spaces\n","# text = re.sub(r'\\s+', ' ', text).strip()\n","\n","# Save cleaned text\n","cleaned_path = file_path.replace('.txt', '_cleaned.txt')\n","with open(cleaned_path, 'w') as f:\n","    f.write(text)\n","\n","cleaned_path"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"tMK-nKzUWL4z","executionInfo":{"status":"ok","timestamp":1763442444937,"user_tz":-330,"elapsed":48,"user":{"displayName":"Venkata Sarath Chandra Galla ic40044","userId":"08935175430182167547"}},"outputId":"342b2855-34e8-48c4-eb7b-f91a6e88f128"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/Test_28_Adnew_wav/e5a/Srtformatissue/Chapter 5A - Use of Growing and Rooting Media in Floriculture_cleaned.txt'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["Text to Srt Format rectifier"],"metadata":{"id":"IIExio9X0mhw"}},{"cell_type":"code","source":["from google.colab import drive, userdata\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tl0SoYU08IKn","executionInfo":{"status":"ok","timestamp":1764224018670,"user_tz":-330,"elapsed":23567,"user":{"displayName":"Venkata Sarath Chandra Galla ic40044","userId":"08935175430182167547"}},"outputId":"2dde24b9-1f73-4013-f8b3-4dcb8f35bedd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","import re\n","\n","def normalize_timestamp(ts: str) -> str:\n","    \"\"\"\n","    Normalize timestamp to 'HH:MM:SS,mmm' format.\n","    Handles missing hours and malformed parts.\n","    \"\"\"\n","    ts = ts.strip().replace('.', ',')\n","    # Split at comma for milliseconds\n","    if ',' in ts:\n","        time_part, ms = ts.split(',', 1)\n","        ms = re.sub(r'\\D', '', ms)[:3].ljust(3, '0')\n","    else:\n","        time_part, ms = ts, '000'\n","    parts = time_part.split(':')\n","    # Fill missing parts\n","    if len(parts) == 1:\n","        h, m, s = 0, 0, parts[0]\n","    elif len(parts) == 2:\n","        h, m, s = 0, parts[0], parts[1]\n","    else:\n","        h, m, s = parts[-3], parts[-2], parts[-1]\n","    try:\n","        return f\"{int(h):02d}:{int(m):02d}:{int(s):02d},{ms}\"\n","    except:\n","        return \"00:00:00,000\"\n","\n","\n","def fix_srt_file(input_path, output_path):\n","    \"\"\"\n","    Reads one .srt/.txt file, fixes timestamp formatting,\n","    and saves a new valid .srt file.\n","    \"\"\"\n","    with open(input_path, 'r', encoding='utf-8', errors='ignore') as f:\n","        lines = f.readlines()\n","\n","    new_lines = []\n","    ts_pattern = re.compile(\n","        r'(\\d{1,2}:?\\d{1,2}:?\\d{1,2}[.,]?\\d*)\\s*[-‚Äì>]+\\s*(\\d{1,2}:?\\d{1,2}:?\\d{1,2}[.,]?\\d*)'\n","    )\n","\n","    for line in lines:\n","        match = ts_pattern.search(line)\n","        if match:\n","            start, end = match.groups()\n","            start = normalize_timestamp(start)\n","            end = normalize_timestamp(end)\n","            new_lines.append(f\"{start} --> {end}\\n\")\n","        else:\n","            new_lines.append(line)\n","\n","    with open(output_path, 'w', encoding='utf-8') as f:\n","        f.writelines(new_lines)\n","\n","\n","def process_folder(input_folder, output_folder):\n","    \"\"\"\n","    Process all .srt/.txt files in a folder recursively,\n","    writing fixed versions to output_folder.\n","    \"\"\"\n","    os.makedirs(output_folder, exist_ok=True)\n","\n","    for root, _, files in os.walk(input_folder):\n","        for file in files:\n","            if file.lower().endswith(('.srt', '.txt')):\n","                input_path = os.path.join(root, file)\n","                rel_path = os.path.relpath(input_path, input_folder)\n","                output_path = os.path.join(output_folder, os.path.splitext(rel_path)[0] + '.srt')\n","\n","                os.makedirs(os.path.dirname(output_path), exist_ok=True)\n","                print(f\"Fixing: {rel_path}\")\n","                fix_srt_file(input_path, output_path)\n","\n","    print(\"\\n All files processed and saved in:\", output_folder)\n","\n","\n","\n","if __name__ == \"__main__\":\n","    input_folder = \"/content/drive/My Drive/Test1/Srtformatissue/\"\n","    output_folder = \"/content/drive/My Drive/Test1/Fixed_srt/\"\n","\n","    process_folder(input_folder, output_folder)\n"],"metadata":{"id":"Gvc9-VnY0ldk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764224028634,"user_tz":-330,"elapsed":2293,"user":{"displayName":"Venkata Sarath Chandra Galla ic40044","userId":"08935175430182167547"}},"outputId":"1a813f3e-e987-4950-c988-5b73c5d54c48"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fixing: Chapter 1A - Introduction to DTP.txt\n","Fixing: Copy of Chapter 1A - Introduction to DTP.txt\n","Fixing: Copy of Chapter 1A - Introduction to DTP (2).txt\n","Fixing: Copy of Chapter 1A - Introduction to DTP (1).txt\n","\n"," All files processed and saved in: /content/drive/My Drive/Test1/Fixed_srt/\n"]}]},{"cell_type":"markdown","source":["# Gemini MT (still testing for improvement)"],"metadata":{"id":"2s2hvX6U00uU"}},{"cell_type":"code","source":["from google import genai\n","from google.colab import drive, userdata\n","import os\n","import re\n","import time\n","\n","# === Mount Google Drive and API ===\n","drive.mount('/content/drive')\n","os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n","client = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])\n","\n","# === Paths ===\n","base_dir = \"/content/drive/My Drive/OpenAI_API_pipeline\"\n","asr_dir = os.path.join(base_dir, \"asr\")  # input SRTs\n","mt_dir = os.path.join(base_dir, \"mt\",\"gemini_2.5_pro\")   # translated output\n","os.makedirs(mt_dir, exist_ok=True)\n","\n","target_language = \"Telugu\"\n","print(\"üü¢ Ready ‚Äî Processing all .srt files...\")\n","\n","# === SRT parsing pattern ===\n","pattern = r\"(\\d+)\\s+([\\d:,]+ --> [\\d:,]+)\\s+(.+?)(?=\\n\\d+\\n|$)\"\n","\n","def translate_batch(lines):\n","    \"\"\"Translate list of subtitle text chunks at once with Gemini.\"\"\"\n","    joined_text = \"\\n\".join(lines)\n","    prompt = f\"\"\"\n","You are a professional subtitle translator for Indic languages.\n","\n","Translate the following subtitle dialogue into {target_language}.\n","Preserve meaning. Keep subtitles short and natural.\n","Do NOT translate numbers or timestamps.\n","Return one line per subtitle, in order.\n","\n","Text:\n","{joined_text}\n","\"\"\"\n","    for _ in range(3):  # retry logic\n","        try:\n","            response = client.models.generate_content(\n","                model=\"gemini-2.5-pro\",  # or gemini-2.0-pro if you have access\n","                contents=prompt\n","            )\n","            # Gemini's response object\n","            result_text = response.text.strip()\n","            return result_text.split(\"\\n\")\n","        except Exception as e:\n","            print(\"Retrying batch due to error:\", e)\n","            time.sleep(3)\n","    return [\"\"] * len(lines)\n","\n","\n","# === Loop over all SRT files ===\n","for f_name in os.listdir(asr_dir):\n","    if not f_name.lower().endswith(\".srt\"):\n","        continue\n","\n","    input_file = os.path.join(asr_dir, f_name)\n","    print(f\"\\nüé¨ Processing: {f_name}\")\n","\n","    with open(input_file, 'r', encoding='utf-8') as f:\n","        content = f.read()\n","\n","    entries = re.findall(pattern, content, flags=re.DOTALL)\n","    print(f\"   ‚Üí {len(entries)} subtitles detected\")\n","\n","    translated_entries = []\n","    translated_text_only = []\n","\n","    batch_size = 15\n","    for i in range(0, len(entries), batch_size):\n","        batch = entries[i:i+batch_size]\n","        orig_texts = [t[2].strip() for t in batch]\n","\n","        translated_batch = translate_batch(orig_texts)\n","\n","        for (num, ts, _), trans in zip(batch, translated_batch):\n","            translated_entries.append(f\"{num}\\n{ts}\\n{trans}\\n\")\n","            translated_text_only.append(trans)\n","\n","        print(f\"   ‚úÖ Translated segments {i+1}‚Äì{min(i+batch_size,len(entries))}\")\n","\n","    # Save outputs\n","    base = os.path.splitext(f_name)[0]\n","    srt_out = os.path.join(mt_dir, f\"{base}_{target_language}.srt\")\n","    txt_out = os.path.join(mt_dir, f\"{base}_{target_language}.txt\")\n","\n","    with open(srt_out, \"w\", encoding='utf-8') as f:\n","        f.write(\"\\n\".join(translated_entries))\n","\n","    with open(txt_out, \"w\", encoding='utf-8') as f:\n","        f.write(\"\\n\".join(translated_text_only))\n","\n","    print(f\"   üìÅ Saved ‚Üí {srt_out}\")\n","    print(f\"   üìÑ Saved ‚Üí {txt_out}\")\n","\n","print(\"\\n‚úÖ All files translated successfully!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w4VRkWuBm0K3","executionInfo":{"status":"ok","timestamp":1762426693193,"user_tz":-330,"elapsed":1292665,"user":{"displayName":"Venkata Sarath Chandra Galla ic40044","userId":"08935175430182167547"}},"outputId":"6417021a-018c-4f01-b6a9-1dcf2347cc48"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","üü¢ Ready ‚Äî Processing all .srt files...\n","\n","üé¨ Processing: Chapter 6A - Sucessful Entreuprenuer Journey.srt\n","   ‚Üí 139 subtitles detected\n","   ‚úÖ Translated segments 1‚Äì15\n","   ‚úÖ Translated segments 16‚Äì30\n","   ‚úÖ Translated segments 31‚Äì45\n","   ‚úÖ Translated segments 46‚Äì60\n","Retrying batch due to error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n","Retrying batch due to error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n","Retrying batch due to error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n","   ‚úÖ Translated segments 61‚Äì75\n","   ‚úÖ Translated segments 76‚Äì90\n","   ‚úÖ Translated segments 91‚Äì105\n","   ‚úÖ Translated segments 106‚Äì120\n","   ‚úÖ Translated segments 121‚Äì135\n","   ‚úÖ Translated segments 136‚Äì139\n","   üìÅ Saved ‚Üí /content/drive/My Drive/OpenAI_API_pipeline/mt/gemini_2.5_pro/Chapter 6A - Sucessful Entreuprenuer Journey_Telugu.srt\n","   üìÑ Saved ‚Üí /content/drive/My Drive/OpenAI_API_pipeline/mt/gemini_2.5_pro/Chapter 6A - Sucessful Entreuprenuer Journey_Telugu.txt\n","\n","üé¨ Processing: Chapter 5B - The Concept of Book Keeping and its Fundamental.srt\n","   ‚Üí 285 subtitles detected\n","   ‚úÖ Translated segments 1‚Äì15\n","   ‚úÖ Translated segments 16‚Äì30\n","   ‚úÖ Translated segments 31‚Äì45\n","Retrying batch due to error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n","   ‚úÖ Translated segments 46‚Äì60\n","   ‚úÖ Translated segments 61‚Äì75\n","   ‚úÖ Translated segments 76‚Äì90\n","Retrying batch due to error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n","   ‚úÖ Translated segments 91‚Äì105\n","   ‚úÖ Translated segments 106‚Äì120\n","   ‚úÖ Translated segments 121‚Äì135\n","   ‚úÖ Translated segments 136‚Äì150\n","   ‚úÖ Translated segments 151‚Äì165\n","   ‚úÖ Translated segments 166‚Äì180\n","   ‚úÖ Translated segments 181‚Äì195\n","   ‚úÖ Translated segments 196‚Äì210\n","Retrying batch due to error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n","   ‚úÖ Translated segments 211‚Äì225\n","   ‚úÖ Translated segments 226‚Äì240\n","   ‚úÖ Translated segments 241‚Äì255\n","   ‚úÖ Translated segments 256‚Äì270\n","   ‚úÖ Translated segments 271‚Äì285\n","   üìÅ Saved ‚Üí /content/drive/My Drive/OpenAI_API_pipeline/mt/gemini_2.5_pro/Chapter 5B - The Concept of Book Keeping and its Fundamental_Telugu.srt\n","   üìÑ Saved ‚Üí /content/drive/My Drive/OpenAI_API_pipeline/mt/gemini_2.5_pro/Chapter 5B - The Concept of Book Keeping and its Fundamental_Telugu.txt\n","\n","‚úÖ All files translated successfully!\n"]}]},{"cell_type":"markdown","source":["# Gemini TTS"],"metadata":{"id":"oQCfcl_y1GA8"}},{"cell_type":"code","source":["!pip install -U -q \"google-genai>=1.16.1\"\n","# !pip install pysrt\n","\n","from google.colab import drive, userdata\n","import io\n","import json\n","import re\n","import wave\n","import os\n","import base64\n","import struct\n","import shutil\n","import pysrt, time\n","\n","from IPython.display import Audio, display, HTML, Markdown\n","from google import genai\n","from google.genai import types\n","from google.genai.types import GenerateContentConfig, Tool\n","\n","# -------------------------------\n","# Mount Google Drive\n","# -------------------------------\n","GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n","drive.mount('/content/drive', force_remount=True)\n","\n","# Initialize client\n","client = genai.Client(api_key=GOOGLE_API_KEY)\n","\n","\n","# -------------------------------\n","# Helper: parse .srt into segments\n","# -------------------------------\n","def parse_srt(path):\n","    subs = pysrt.open(path)\n","    segments = []\n","    for sub in subs:\n","        start = sub.start.hours*3600 + sub.start.minutes*60 + sub.start.seconds + sub.start.milliseconds/1000\n","        end   = sub.end.hours*3600   + sub.end.minutes*60   + sub.end.seconds   + sub.end.milliseconds/1000\n","        text = sub.text.replace(\"\\n\", \" \").strip()\n","        segments.append((start, end, text))\n","    return segments\n","\n","\n","# -------------------------------\n","# Helper: write .wav file\n","# -------------------------------\n","def wave_file(filename, pcm, channels=1, rate=24000, sample_width=2):\n","    print(f\"\\nWriting audio file with parameters:\")\n","    print(f\"Channels: {channels}\")\n","    print(f\"Sample rate: {rate}\")\n","    print(f\"Sample width: {sample_width}\")\n","    print(f\"Data length: {len(pcm)} bytes\")\n","\n","    with wave.open(filename, \"wb\") as wf:\n","        wf.setnchannels(channels)\n","        wf.setsampwidth(sample_width)\n","        wf.setframerate(rate)\n","        wf.writeframes(pcm)\n","\n","\n","# -------------------------------\n","# NEW Helper: Safe TTS with retry\n","# -------------------------------\n","def get_tts_audio(client, prompt, voice, retries=5, delay=5):\n","    \"\"\"Call Gemini TTS with retry logic and safe extraction.\"\"\"\n","    for attempt in range(retries):\n","        try:\n","            response = client.models.generate_content(\n","                model=\"gemini-2.5-pro-preview-tts\",\n","                contents=prompt,\n","                config=types.GenerateContentConfig(\n","                    response_modalities=[\"audio\"],\n","                    speech_config=types.SpeechConfig(\n","                        voice_config=types.VoiceConfig(\n","                            prebuilt_voice_config=types.PrebuiltVoiceConfig(\n","                                voice_name=voice\n","                            )\n","                        )\n","                    ),\n","                ),\n","            )\n","\n","            # --- Safe extraction block ---\n","            data = None\n","            try:\n","                data = response.candidates[0].content.parts[0].inline_data.data\n","            except Exception:\n","                if hasattr(response.candidates[0].content, \"inline_data\"):\n","                    data = response.candidates[0].content.inline_data.data\n","                elif hasattr(response, \"audio\") and hasattr(response.audio, \"data\"):\n","                    data = response.audio.data\n","\n","            if data:\n","                return data  # ‚úÖ success\n","            else:\n","                print(f\"‚ö†Ô∏è No audio returned on attempt {attempt+1}. Retrying...\")\n","                time.sleep(delay)\n","        except Exception as e:\n","            print(f\"‚ö†Ô∏è TTS error on attempt {attempt+1}: {e}\")\n","            time.sleep(delay)\n","    return None  # ‚ùå all retries failed\n","\n","\n","# -------------------------------\n","# Input + setup\n","# -------------------------------\n","srt_file_path = '/content/drive/MyDrive/aa/test2_Tamil.srt'  # replace with your path\n","VOICE = 'Kore'\n","\n","segments = parse_srt(srt_file_path)\n","print(f\"Found {len(segments)} subtitle segments.\")\n","\n","base_name = os.path.splitext(os.path.basename(srt_file_path))[0]\n","output_dir = f'/content/drive/MyDrive/aa/{base_name}_segments'\n","os.makedirs(output_dir, exist_ok=True)\n","\n","failed_log = os.path.join(output_dir, \"failed_segments.txt\")\n","\n","# -------------------------------\n","# Main processing loop\n","# -------------------------------\n","for idx, (start, end, text) in enumerate(segments, 1):\n","    if len(text.strip()) < 5:\n","        print(f\"‚ö†Ô∏è Skipping too-short segment {idx}: '{text}'\")\n","        continue\n","\n","    PROMPT = f\"Speak in Indian female Tamil with an educational tone: {text}\"\n","    print(f\"\\nProcessing segment {idx} ({start:.2f}s ‚Üí {end:.2f}s): {text[:60]}...\")\n","\n","    data = get_tts_audio(client, PROMPT, VOICE)\n","    if not data:\n","        print(f\"‚ùå Skipping segment {idx} ‚Äî no audio after retries.\")\n","        with open(failed_log, \"a\") as log:\n","            log.write(f\"{idx}: {text}\\n\")\n","        continue\n","\n","    # Save audio\n","    rate = 24000\n","    file_name = f\"{idx:03d}.wav\"\n","    print(f\"\\nSaving sample rate: {rate}\")\n","    wave_file(file_name, data, rate=rate)\n","\n","    # Copy to Drive\n","    destination_path = os.path.join(output_dir, file_name)\n","    shutil.copy(f\"/content/{file_name}\", destination_path)\n","    display(Audio(destination_path))\n","\n","print(f\"\\n‚úÖ All segments saved in: {output_dir}\")\n","print(f\"üìÑ Failed segments (if any) logged to: {failed_log}\")\n"],"metadata":{"id":"oxdf899TjdEk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["audio merge"],"metadata":{"id":"xpz6ZIHw6m1c"}},{"cell_type":"code","source":["import subprocess\n","\n","def merge_segments_ffmpeg_timed(segments, segments_dir, output_path, sample_rate=24000):\n","    \"\"\"\n","    Merge segments into a single time-aligned audio track using FFmpeg filter_complex.\n","    Each segment is placed at its exact SRT start time.\n","    \"\"\"\n","    print(\"\\nüéØ Performing precise timeline merge using FFmpeg...\")\n","\n","    filter_parts = []\n","    inputs = []\n","\n","    for i, (start, end, text) in enumerate(segments, 1):\n","        seg_path = os.path.join(segments_dir, f\"{i:03d}.wav\")\n","        if not os.path.exists(seg_path):\n","            print(f\"‚ö†Ô∏è Skipping missing segment {i:03d}\")\n","            continue\n","\n","        delay_ms = int(start * 1000)  # convert to milliseconds\n","        inputs += [\"-i\", seg_path]\n","        # Apply delay via adelay filter\n","        filter_parts.append(f\"[{i-1}:a]adelay={delay_ms}|{delay_ms}[a{i}]\")\n","\n","    # Combine all delayed audio tracks\n","    filter_complex = \"; \".join(filter_parts) + f\"; {' '.join(f'[a{i}]' for i in range(1, len(filter_parts)+1))}amix=inputs={len(filter_parts)}:normalize=0[aout]\"\n","\n","    cmd = [\n","        \"ffmpeg\", \"-y\",\n","        *inputs,\n","        \"-filter_complex\", filter_complex,\n","        \"-map\", \"[aout]\",\n","        \"-ar\", str(sample_rate),\n","        \"-ac\", \"1\",\n","        \"-c:a\", \"pcm_s16le\",\n","        output_path\n","    ]\n","\n","    print(f\"\\nRunning FFmpeg command:\\n{' '.join(cmd)}\\n\")\n","    subprocess.run(cmd, check=True)\n","    print(f\"‚úÖ Final aligned audio saved at: {output_path}\")\n","\n","final_output = f\"/content/drive/MyDrive/aa/{base_name}_merged_timed_Tamil.wav\"\n","merge_segments_ffmpeg_timed(segments, output_dir, final_output)\n","\n"],"metadata":{"id":"CCD9htfq6lxF"},"execution_count":null,"outputs":[]}]}