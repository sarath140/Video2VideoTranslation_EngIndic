{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Gemini ASR+MT"
      ],
      "metadata": {
        "id": "HB554x0fP-XN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIsBOHvCTJFa",
        "outputId": "5f191c4a-ad99-4d70-c7d4-db9d24862092"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4GQSlCE3QB-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gemini ASR"
      ],
      "metadata": {
        "id": "49_Ha-ed0OQp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3BXefuNz3EV"
      },
      "outputs": [],
      "source": [
        "# ========================\n",
        "# INSTALL & IMPORTS\n",
        "# ========================\n",
        "!pip install -q google-generativeai pydub tqdm librosa\n",
        "\n",
        "import os\n",
        "import io\n",
        "from google.colab import drive, userdata\n",
        "import google.generativeai as genai\n",
        "from pydub import AudioSegment\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ========================\n",
        "# SETUP\n",
        "# ========================\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Securely load your Gemini API key from Colab secrets\n",
        "api_key = userdata.get(\"GOOGLE_API_KEY\")\n",
        "if not api_key:\n",
        "    raise ValueError(\"‚ùå No GOOGLE_API_KEY found in Colab secrets! Add it under 'More ‚Üí Secrets'.\")\n",
        "\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "# Choose your model\n",
        "model = genai.GenerativeModel(\"models/gemini-2.5-pro\")\n",
        "\n",
        "# Input/output folders in Google Drive\n",
        "base_dir = \"/content/drive/MyDrive/Test_28_Adnew_wav/\"\n",
        "input_dir = \"/content/drive/MyDrive/Test_28_Adnew_wav/Tamil/\"\n",
        "output_dir = os.path.join(base_dir, \"Test_28_srtimprv\",\"Srt1\")\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# ========================\n",
        "# HELPER FUNCTIONS\n",
        "# ========================\n",
        "\n",
        "def transcribe_audio_file(file_path):\n",
        "    \"\"\"Transcribe full audio file without splitting.\"\"\"\n",
        "    audio = AudioSegment.from_wav(file_path)\n",
        "    buffer = io.BytesIO()\n",
        "    audio.export(buffer, format=\"wav\")\n",
        "    audio_bytes = buffer.getvalue()\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content([\n",
        "            {\"mime_type\": \"audio/wav\", \"data\": audio_bytes},\n",
        "            \"\"\"\n",
        "            Your are a Subtitle Generator:\n",
        "            Transcribe this audio exactly as spoken in Tamil (no extra comments, no filler words) in the .srt format(Subtitle Format):\n",
        "\n",
        "            1\n",
        "            00:00:15,362 --> 00:00:21,789\n",
        "            ‡§Ö‡§¨ ‡§π‡§Æ ‡§ú‡§æ‡§®‡•á‡§Ç‡§ó‡•á ‡§ï‡•à‡§Ç‡§°‡§≤‡•ç‡§∏ ‡§Æ‡•á‡§Ç ‡§ï‡•ç‡§Ø‡§æ ‡§ï‡•ç‡§Ø‡§æ ‡§ö‡•Ä‡§ú‡§º‡•ã‡§Ç ‡§ï‡•Ä ‡§ú‡§º‡§∞‡•Ç‡§∞‡§§ ‡§™‡§°‡§º‡§§‡•Ä ‡§π‡•à ‡§î‡§∞ ‡§â‡§®‡§ï‡•ã ‡§π‡§Æ ‡§ï‡§π‡§æ‡§Å ‡§∏‡•á ‡§ñ‡§º‡§∞‡•Ä‡§¶ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç\n",
        "\n",
        "            2\n",
        "            00:00:21,922 --> 00:00:27,422\n",
        "            ‡§§‡•ã ‡§∏‡§¨‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§ï‡•à‡§Ç‡§°‡§≤ ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§π‡§Æ‡•á‡§Ç ‡§°‡§¨‡§≤ ‡§¨‡•â‡§Ø‡§≤‡§∞ ‡§ï‡•Ä ‡§ú‡§º‡§∞‡•Ç‡§∞‡§§ ‡§™‡§°‡§º‡§§‡•Ä ‡§π‡•à ‡§Ø‡•á\n",
        "\n",
        "            3\n",
        "            00:00:27,617 --> 00:00:29,853\n",
        "            ‡§á‡§∏ ‡§§‡§∞‡§π ‡§ï‡§æ ‡§Ø‡•á ‡§á‡§Ç‡§°‡§ï‡•ç‡§∂‡§® ‡§π‡•à\n",
        "\n",
        "            and so on...\n",
        "\n",
        "            The transcription should strictly follow the format above, where:\n",
        "            - **Timestamps** are in the format of HH:MM:SS,SSS --> HH:MM:SS,SSS (with millisecond precision)(Hours:Minutes:Seconds,milliseconds).\n",
        "            - Each entry should have a **sequential index** starting from 1 (e.g., 1, 2, 3, ...).\n",
        "            - Even if Hours are not, Keep the Hours format in timestamp like this: 00:00:29,854 --> 00:00:34,500 not like this 00:29,854 --> 00:34,500 or 29,854 --> 34,500.\n",
        "            - The spoken text should be captured **exactly as it is spoken**, without adding or removing words(but remove filler words).\n",
        "            - If there is **silence** or a pause, mark the duration with a timestamp like this:\n",
        "              ```\n",
        "              4\n",
        "              00:00:29,854 --> 00:00:34,500\n",
        "              [Silence]\n",
        "              ```\n",
        "            - Include **Speaker labels** (e.g., Speaker 1, Speaker 2) where relevant if multiple speakers are detected.\n",
        "\n",
        "            Please ensure the output strictly follows the SRT format. Thank you!\n",
        "            \"\"\"\n",
        "        ])\n",
        "\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        print(\"‚ùå Error:\", e)\n",
        "        return \"\"\n",
        "\n",
        "# ========================\n",
        "# MAIN PROCESS\n",
        "# ========================\n",
        "\n",
        "for filename in os.listdir(input_dir):\n",
        "    if filename.lower().endswith(\".wav\"):\n",
        "        file_path = os.path.join(input_dir, filename)\n",
        "        print(f\"\\nüéß Transcribing full audio: {filename}\")\n",
        "\n",
        "        # Get full transcription\n",
        "        text = transcribe_audio_file(file_path)\n",
        "\n",
        "        # Save TXT file\n",
        "        txt_output = os.path.join(output_dir, filename.replace(\".wav\", \".txt\"))\n",
        "        with open(txt_output, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(text)\n",
        "\n",
        "        print(f\"‚úÖ Done: {filename}\")\n",
        "        print(f\"üìÑ TXT saved to: {txt_output}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text to Srt Format rectifier"
      ],
      "metadata": {
        "id": "IIExio9X0mhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "def normalize_timestamp(ts: str) -> str:\n",
        "    \"\"\"\n",
        "    Normalize timestamp to 'HH:MM:SS,mmm' format.\n",
        "    Handles missing hours and malformed parts.\n",
        "    \"\"\"\n",
        "    ts = ts.strip().replace('.', ',')\n",
        "    # Split at comma for milliseconds\n",
        "    if ',' in ts:\n",
        "        time_part, ms = ts.split(',', 1)\n",
        "        ms = re.sub(r'\\D', '', ms)[:3].ljust(3, '0')\n",
        "    else:\n",
        "        time_part, ms = ts, '000'\n",
        "    parts = time_part.split(':')\n",
        "    # Fill missing parts\n",
        "    if len(parts) == 1:\n",
        "        h, m, s = 0, 0, parts[0]\n",
        "    elif len(parts) == 2:\n",
        "        h, m, s = 0, parts[0], parts[1]\n",
        "    else:\n",
        "        h, m, s = parts[-3], parts[-2], parts[-1]\n",
        "    try:\n",
        "        return f\"{int(h):02d}:{int(m):02d}:{int(s):02d},{ms}\"\n",
        "    except:\n",
        "        return \"00:00:00,000\"\n",
        "\n",
        "\n",
        "def fix_srt_file(input_path, output_path):\n",
        "    \"\"\"\n",
        "    Reads one .srt/.txt file, fixes timestamp formatting,\n",
        "    and saves a new valid .srt file.\n",
        "    \"\"\"\n",
        "    with open(input_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    new_lines = []\n",
        "    ts_pattern = re.compile(\n",
        "        r'(\\d{1,2}:?\\d{1,2}:?\\d{1,2}[.,]?\\d*)\\s*[-‚Äì>]+\\s*(\\d{1,2}:?\\d{1,2}:?\\d{1,2}[.,]?\\d*)'\n",
        "    )\n",
        "\n",
        "    for line in lines:\n",
        "        match = ts_pattern.search(line)\n",
        "        if match:\n",
        "            start, end = match.groups()\n",
        "            start = normalize_timestamp(start)\n",
        "            end = normalize_timestamp(end)\n",
        "            new_lines.append(f\"{start} --> {end}\\n\")\n",
        "        else:\n",
        "            new_lines.append(line)\n",
        "\n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        f.writelines(new_lines)\n",
        "\n",
        "\n",
        "def process_folder(input_folder, output_folder):\n",
        "    \"\"\"\n",
        "    Process all .srt/.txt files in a folder recursively,\n",
        "    writing fixed versions to output_folder.\n",
        "    \"\"\"\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    for root, _, files in os.walk(input_folder):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.srt', '.txt')):\n",
        "                input_path = os.path.join(root, file)\n",
        "                rel_path = os.path.relpath(input_path, input_folder)\n",
        "                output_path = os.path.join(output_folder, os.path.splitext(rel_path)[0] + '.srt')\n",
        "\n",
        "                os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "                print(f\"Fixing: {rel_path}\")\n",
        "                fix_srt_file(input_path, output_path)\n",
        "\n",
        "    print(\"\\n All files processed and saved in:\", output_folder)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_folder = \"/content/drive/My Drive/Test_28_Adnew_wav/Test_28_Gemini25pro_asr/Tamil/Srt\"\n",
        "    output_folder = \"/content/drive/My Drive/Test_28_Adnew_wav/Test_28_Gemini25pro_asr/Tamil/Fixed_srt\"\n",
        "\n",
        "    process_folder(input_folder, output_folder)\n"
      ],
      "metadata": {
        "id": "Gvc9-VnY0ldk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gemini MT (still testing for improvement)"
      ],
      "metadata": {
        "id": "2s2hvX6U00uU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.colab import drive, userdata\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "\n",
        "# === Mount Google Drive and API ===\n",
        "drive.mount('/content/drive')\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "client = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "\n",
        "# === Paths ===\n",
        "base_dir = \"/content/drive/My Drive/OpenAI_API_pipeline\"\n",
        "asr_dir = os.path.join(base_dir, \"asr\")  # input SRTs\n",
        "mt_dir = os.path.join(base_dir, \"mt\",\"gemini_2.5_pro\")   # translated output\n",
        "os.makedirs(mt_dir, exist_ok=True)\n",
        "\n",
        "target_language = \"Telugu\"\n",
        "print(\"üü¢ Ready ‚Äî Processing all .srt files...\")\n",
        "\n",
        "# === SRT parsing pattern ===\n",
        "pattern = r\"(\\d+)\\s+([\\d:,]+ --> [\\d:,]+)\\s+(.+?)(?=\\n\\d+\\n|$)\"\n",
        "\n",
        "def translate_batch(lines):\n",
        "    \"\"\"Translate list of subtitle text chunks at once with Gemini.\"\"\"\n",
        "    joined_text = \"\\n\".join(lines)\n",
        "    prompt = f\"\"\"\n",
        "You are a professional subtitle translator for Indic languages.\n",
        "\n",
        "Translate the following subtitle dialogue into {target_language}.\n",
        "Preserve meaning. Keep subtitles short and natural.\n",
        "Do NOT translate numbers or timestamps.\n",
        "Return one line per subtitle, in order.\n",
        "\n",
        "Text:\n",
        "{joined_text}\n",
        "\"\"\"\n",
        "    for _ in range(3):  # retry logic\n",
        "        try:\n",
        "            response = client.models.generate_content(\n",
        "                model=\"gemini-2.5-pro\",  # or gemini-2.0-pro if you have access\n",
        "                contents=prompt\n",
        "            )\n",
        "            # Gemini's response object\n",
        "            result_text = response.text.strip()\n",
        "            return result_text.split(\"\\n\")\n",
        "        except Exception as e:\n",
        "            print(\"Retrying batch due to error:\", e)\n",
        "            time.sleep(3)\n",
        "    return [\"\"] * len(lines)\n",
        "\n",
        "\n",
        "# === Loop over all SRT files ===\n",
        "for f_name in os.listdir(asr_dir):\n",
        "    if not f_name.lower().endswith(\".srt\"):\n",
        "        continue\n",
        "\n",
        "    input_file = os.path.join(asr_dir, f_name)\n",
        "    print(f\"\\nüé¨ Processing: {f_name}\")\n",
        "\n",
        "    with open(input_file, 'r', encoding='utf-8') as f:\n",
        "        content = f.read()\n",
        "\n",
        "    entries = re.findall(pattern, content, flags=re.DOTALL)\n",
        "    print(f\"   ‚Üí {len(entries)} subtitles detected\")\n",
        "\n",
        "    translated_entries = []\n",
        "    translated_text_only = []\n",
        "\n",
        "    batch_size = 15\n",
        "    for i in range(0, len(entries), batch_size):\n",
        "        batch = entries[i:i+batch_size]\n",
        "        orig_texts = [t[2].strip() for t in batch]\n",
        "\n",
        "        translated_batch = translate_batch(orig_texts)\n",
        "\n",
        "        for (num, ts, _), trans in zip(batch, translated_batch):\n",
        "            translated_entries.append(f\"{num}\\n{ts}\\n{trans}\\n\")\n",
        "            translated_text_only.append(trans)\n",
        "\n",
        "        print(f\"   ‚úÖ Translated segments {i+1}‚Äì{min(i+batch_size,len(entries))}\")\n",
        "\n",
        "    # Save outputs\n",
        "    base = os.path.splitext(f_name)[0]\n",
        "    srt_out = os.path.join(mt_dir, f\"{base}_{target_language}.srt\")\n",
        "    txt_out = os.path.join(mt_dir, f\"{base}_{target_language}.txt\")\n",
        "\n",
        "    with open(srt_out, \"w\", encoding='utf-8') as f:\n",
        "        f.write(\"\\n\".join(translated_entries))\n",
        "\n",
        "    with open(txt_out, \"w\", encoding='utf-8') as f:\n",
        "        f.write(\"\\n\".join(translated_text_only))\n",
        "\n",
        "    print(f\"   üìÅ Saved ‚Üí {srt_out}\")\n",
        "    print(f\"   üìÑ Saved ‚Üí {txt_out}\")\n",
        "\n",
        "print(\"\\n‚úÖ All files translated successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4VRkWuBm0K3",
        "outputId": "6417021a-018c-4f01-b6a9-1dcf2347cc48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "üü¢ Ready ‚Äî Processing all .srt files...\n",
            "\n",
            "üé¨ Processing: Chapter 6A - Sucessful Entreuprenuer Journey.srt\n",
            "   ‚Üí 139 subtitles detected\n",
            "   ‚úÖ Translated segments 1‚Äì15\n",
            "   ‚úÖ Translated segments 16‚Äì30\n",
            "   ‚úÖ Translated segments 31‚Äì45\n",
            "   ‚úÖ Translated segments 46‚Äì60\n",
            "Retrying batch due to error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
            "Retrying batch due to error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
            "Retrying batch due to error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
            "   ‚úÖ Translated segments 61‚Äì75\n",
            "   ‚úÖ Translated segments 76‚Äì90\n",
            "   ‚úÖ Translated segments 91‚Äì105\n",
            "   ‚úÖ Translated segments 106‚Äì120\n",
            "   ‚úÖ Translated segments 121‚Äì135\n",
            "   ‚úÖ Translated segments 136‚Äì139\n",
            "   üìÅ Saved ‚Üí /content/drive/My Drive/OpenAI_API_pipeline/mt/gemini_2.5_pro/Chapter 6A - Sucessful Entreuprenuer Journey_Telugu.srt\n",
            "   üìÑ Saved ‚Üí /content/drive/My Drive/OpenAI_API_pipeline/mt/gemini_2.5_pro/Chapter 6A - Sucessful Entreuprenuer Journey_Telugu.txt\n",
            "\n",
            "üé¨ Processing: Chapter 5B - The Concept of Book Keeping and its Fundamental.srt\n",
            "   ‚Üí 285 subtitles detected\n",
            "   ‚úÖ Translated segments 1‚Äì15\n",
            "   ‚úÖ Translated segments 16‚Äì30\n",
            "   ‚úÖ Translated segments 31‚Äì45\n",
            "Retrying batch due to error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
            "   ‚úÖ Translated segments 46‚Äì60\n",
            "   ‚úÖ Translated segments 61‚Äì75\n",
            "   ‚úÖ Translated segments 76‚Äì90\n",
            "Retrying batch due to error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
            "   ‚úÖ Translated segments 91‚Äì105\n",
            "   ‚úÖ Translated segments 106‚Äì120\n",
            "   ‚úÖ Translated segments 121‚Äì135\n",
            "   ‚úÖ Translated segments 136‚Äì150\n",
            "   ‚úÖ Translated segments 151‚Äì165\n",
            "   ‚úÖ Translated segments 166‚Äì180\n",
            "   ‚úÖ Translated segments 181‚Äì195\n",
            "   ‚úÖ Translated segments 196‚Äì210\n",
            "Retrying batch due to error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
            "   ‚úÖ Translated segments 211‚Äì225\n",
            "   ‚úÖ Translated segments 226‚Äì240\n",
            "   ‚úÖ Translated segments 241‚Äì255\n",
            "   ‚úÖ Translated segments 256‚Äì270\n",
            "   ‚úÖ Translated segments 271‚Äì285\n",
            "   üìÅ Saved ‚Üí /content/drive/My Drive/OpenAI_API_pipeline/mt/gemini_2.5_pro/Chapter 5B - The Concept of Book Keeping and its Fundamental_Telugu.srt\n",
            "   üìÑ Saved ‚Üí /content/drive/My Drive/OpenAI_API_pipeline/mt/gemini_2.5_pro/Chapter 5B - The Concept of Book Keeping and its Fundamental_Telugu.txt\n",
            "\n",
            "‚úÖ All files translated successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gemini TTS"
      ],
      "metadata": {
        "id": "oQCfcl_y1GA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q \"google-genai>=1.16.1\"\n",
        "# !pip install pysrt\n",
        "\n",
        "from google.colab import drive, userdata\n",
        "import io\n",
        "import json\n",
        "import re\n",
        "import wave\n",
        "import os\n",
        "import base64\n",
        "import struct\n",
        "import shutil\n",
        "import pysrt, time\n",
        "\n",
        "from IPython.display import Audio, display, HTML, Markdown\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from google.genai.types import GenerateContentConfig, Tool\n",
        "\n",
        "# -------------------------------\n",
        "# Mount Google Drive\n",
        "# -------------------------------\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Initialize client\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# Helper: parse .srt into segments\n",
        "# -------------------------------\n",
        "def parse_srt(path):\n",
        "    subs = pysrt.open(path)\n",
        "    segments = []\n",
        "    for sub in subs:\n",
        "        start = sub.start.hours*3600 + sub.start.minutes*60 + sub.start.seconds + sub.start.milliseconds/1000\n",
        "        end   = sub.end.hours*3600   + sub.end.minutes*60   + sub.end.seconds   + sub.end.milliseconds/1000\n",
        "        text = sub.text.replace(\"\\n\", \" \").strip()\n",
        "        segments.append((start, end, text))\n",
        "    return segments\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# Helper: write .wav file\n",
        "# -------------------------------\n",
        "def wave_file(filename, pcm, channels=1, rate=24000, sample_width=2):\n",
        "    print(f\"\\nWriting audio file with parameters:\")\n",
        "    print(f\"Channels: {channels}\")\n",
        "    print(f\"Sample rate: {rate}\")\n",
        "    print(f\"Sample width: {sample_width}\")\n",
        "    print(f\"Data length: {len(pcm)} bytes\")\n",
        "\n",
        "    with wave.open(filename, \"wb\") as wf:\n",
        "        wf.setnchannels(channels)\n",
        "        wf.setsampwidth(sample_width)\n",
        "        wf.setframerate(rate)\n",
        "        wf.writeframes(pcm)\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# NEW Helper: Safe TTS with retry\n",
        "# -------------------------------\n",
        "def get_tts_audio(client, prompt, voice, retries=5, delay=5):\n",
        "    \"\"\"Call Gemini TTS with retry logic and safe extraction.\"\"\"\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            response = client.models.generate_content(\n",
        "                model=\"gemini-2.5-pro-preview-tts\",\n",
        "                contents=prompt,\n",
        "                config=types.GenerateContentConfig(\n",
        "                    response_modalities=[\"audio\"],\n",
        "                    speech_config=types.SpeechConfig(\n",
        "                        voice_config=types.VoiceConfig(\n",
        "                            prebuilt_voice_config=types.PrebuiltVoiceConfig(\n",
        "                                voice_name=voice\n",
        "                            )\n",
        "                        )\n",
        "                    ),\n",
        "                ),\n",
        "            )\n",
        "\n",
        "            # --- Safe extraction block ---\n",
        "            data = None\n",
        "            try:\n",
        "                data = response.candidates[0].content.parts[0].inline_data.data\n",
        "            except Exception:\n",
        "                if hasattr(response.candidates[0].content, \"inline_data\"):\n",
        "                    data = response.candidates[0].content.inline_data.data\n",
        "                elif hasattr(response, \"audio\") and hasattr(response.audio, \"data\"):\n",
        "                    data = response.audio.data\n",
        "\n",
        "            if data:\n",
        "                return data  # ‚úÖ success\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è No audio returned on attempt {attempt+1}. Retrying...\")\n",
        "                time.sleep(delay)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è TTS error on attempt {attempt+1}: {e}\")\n",
        "            time.sleep(delay)\n",
        "    return None  # ‚ùå all retries failed\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# Input + setup\n",
        "# -------------------------------\n",
        "srt_file_path = '/content/drive/MyDrive/aa/test2_Tamil.srt'  # replace with your path\n",
        "VOICE = 'Kore'\n",
        "\n",
        "segments = parse_srt(srt_file_path)\n",
        "print(f\"Found {len(segments)} subtitle segments.\")\n",
        "\n",
        "base_name = os.path.splitext(os.path.basename(srt_file_path))[0]\n",
        "output_dir = f'/content/drive/MyDrive/aa/{base_name}_segments'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "failed_log = os.path.join(output_dir, \"failed_segments.txt\")\n",
        "\n",
        "# -------------------------------\n",
        "# Main processing loop\n",
        "# -------------------------------\n",
        "for idx, (start, end, text) in enumerate(segments, 1):\n",
        "    if len(text.strip()) < 5:\n",
        "        print(f\"‚ö†Ô∏è Skipping too-short segment {idx}: '{text}'\")\n",
        "        continue\n",
        "\n",
        "    PROMPT = f\"Speak in Indian female Tamil with an educational tone: {text}\"\n",
        "    print(f\"\\nProcessing segment {idx} ({start:.2f}s ‚Üí {end:.2f}s): {text[:60]}...\")\n",
        "\n",
        "    data = get_tts_audio(client, PROMPT, VOICE)\n",
        "    if not data:\n",
        "        print(f\"‚ùå Skipping segment {idx} ‚Äî no audio after retries.\")\n",
        "        with open(failed_log, \"a\") as log:\n",
        "            log.write(f\"{idx}: {text}\\n\")\n",
        "        continue\n",
        "\n",
        "    # Save audio\n",
        "    rate = 24000\n",
        "    file_name = f\"{idx:03d}.wav\"\n",
        "    print(f\"\\nSaving sample rate: {rate}\")\n",
        "    wave_file(file_name, data, rate=rate)\n",
        "\n",
        "    # Copy to Drive\n",
        "    destination_path = os.path.join(output_dir, file_name)\n",
        "    shutil.copy(f\"/content/{file_name}\", destination_path)\n",
        "    display(Audio(destination_path))\n",
        "\n",
        "print(f\"\\n‚úÖ All segments saved in: {output_dir}\")\n",
        "print(f\"üìÑ Failed segments (if any) logged to: {failed_log}\")\n"
      ],
      "metadata": {
        "id": "oxdf899TjdEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "audio merge"
      ],
      "metadata": {
        "id": "xpz6ZIHw6m1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "def merge_segments_ffmpeg_timed(segments, segments_dir, output_path, sample_rate=24000):\n",
        "    \"\"\"\n",
        "    Merge segments into a single time-aligned audio track using FFmpeg filter_complex.\n",
        "    Each segment is placed at its exact SRT start time.\n",
        "    \"\"\"\n",
        "    print(\"\\nüéØ Performing precise timeline merge using FFmpeg...\")\n",
        "\n",
        "    filter_parts = []\n",
        "    inputs = []\n",
        "\n",
        "    for i, (start, end, text) in enumerate(segments, 1):\n",
        "        seg_path = os.path.join(segments_dir, f\"{i:03d}.wav\")\n",
        "        if not os.path.exists(seg_path):\n",
        "            print(f\"‚ö†Ô∏è Skipping missing segment {i:03d}\")\n",
        "            continue\n",
        "\n",
        "        delay_ms = int(start * 1000)  # convert to milliseconds\n",
        "        inputs += [\"-i\", seg_path]\n",
        "        # Apply delay via adelay filter\n",
        "        filter_parts.append(f\"[{i-1}:a]adelay={delay_ms}|{delay_ms}[a{i}]\")\n",
        "\n",
        "    # Combine all delayed audio tracks\n",
        "    filter_complex = \"; \".join(filter_parts) + f\"; {' '.join(f'[a{i}]' for i in range(1, len(filter_parts)+1))}amix=inputs={len(filter_parts)}:normalize=0[aout]\"\n",
        "\n",
        "    cmd = [\n",
        "        \"ffmpeg\", \"-y\",\n",
        "        *inputs,\n",
        "        \"-filter_complex\", filter_complex,\n",
        "        \"-map\", \"[aout]\",\n",
        "        \"-ar\", str(sample_rate),\n",
        "        \"-ac\", \"1\",\n",
        "        \"-c:a\", \"pcm_s16le\",\n",
        "        output_path\n",
        "    ]\n",
        "\n",
        "    print(f\"\\nRunning FFmpeg command:\\n{' '.join(cmd)}\\n\")\n",
        "    subprocess.run(cmd, check=True)\n",
        "    print(f\"‚úÖ Final aligned audio saved at: {output_path}\")\n",
        "\n",
        "final_output = f\"/content/drive/MyDrive/aa/{base_name}_merged_timed_Tamil.wav\"\n",
        "merge_segments_ffmpeg_timed(segments, output_dir, final_output)\n",
        "\n"
      ],
      "metadata": {
        "id": "CCD9htfq6lxF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}